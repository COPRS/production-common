spring:
  main:
    banner-mode: "off"
  application:
    name: s1pdgs-ingestion-xbip-s3-trigger

# Logging config
logging:
  config: ${log4j_config:log/log4j2.yml}

process:
  # hostname of the container (derived by 'hostname' command)
  hostname: ${HOSTNAME}

# Ingestion Trigger config
ingestion-trigger:
  # Maximum number of consecutive retries for publishing of ingestion jobs (defaults to 10)
  publish-max-retries: {{if .Values.xbip }}{{.Values.xbip.publishMaxRetries | default "10" }}{{else}} 10 {{end}}
  # Time between retries after unsuccessful publishing of ingestion jobs in millis (defaults to 10000)
  publish-tempo-retry-ms: {{if .Values.xbip }}{{.Values.xbip.publishTempoRetryMs | default "10000" }}{{else}} 10000 {{end}}
  # Pickup point polling interval in millis
  polling-interval-ms: 10000
  polling:
    # Handling of S3 EDRS sessions NOMINAL
      # Pickup path
    - directory: https://${s3.host}${s3.path}NOMINAL/
      # Filename regex for matching files
      matchRegex: ^([A-Za-z_]{4}/)?([0-9A-Za-z_]{1})3([0-9A-Za-z_]{1})/([0-9A-Za-z_/]+)/(ch[0|_]?[1-2]/)?(DCS_[0-9]{2}_([a-zA-Z0-9_]*)_ch([12])_(DSDB|DSIB).*\.(raw|aisp|xml|RAW|AISP|XML))$
      # Filename regex for ignoring files
      ignoreRegex: (^\..*|.*\.tmp$|db.*|^lost\+found$)
      # Kafka topic to put the ingestion jobs for the worker
      topic: t-pdgs-ingestion-jobs-s3-xbip-nominal
      # Product family accociated with the file to be ingested
      family: EDRS_SESSION
      # Name of the station for EDRS sessions (4-letter code)
      stationName: S3_1
      # Mission-ID in upper case (S1,S2,S3..)
      missionId: S3
      # how many days to keep persisted data about inbox files at a minimum ( >= 0)
      station-retention-time: {{ .Values.xbip.stationRetentionTime.s3 }}
      # Set to ingnore files before a specific date (in format "yyyy-MM-ddTHH:mm:ss.SSSZ")
      ignore-files-before-date: {{ .Values.xbip.ignoreFilesBeforeDate.s3 }}
      # file name matcher for session files
      session-name-pattern: ^([A-Za-z_]{4}/)?([0-9A-Za-z_]{1})3([0-9A-Za-z_]{1})/([0-9]+)/(([0-9A-Za-z_/]+)/(ch[0|_]?[1-2]/)?(DCS_[0-9]{2}_([a-zA-Z0-9_]*)_ch([12])_(DSDB|DSIB).*\.(raw|aisp|xml|RAW|AISP|XML)))$
      # group number containing the session name
      session-name-group-index: 5

    # Handling of S3 EDRS sessions RETRANSFER
      # Pickup path
    - directory: https://${s3.host}${s3.path}RETRANSFER/
      # Filename regex for matching files
      matchRegex: ^([A-Za-z_]{4}/)?([0-9A-Za-z_]{1})3([0-9A-Za-z_]{1})/([0-9A-Za-z_/]+)/(ch[0|_]?[1-2]/)?(DCS_[0-9]{2}_([a-zA-Z0-9_]*)_ch([12])_(DSDB|DSIB).*\.(raw|aisp|xml|RAW|AISP|XML))$
      # Filename regex for ignoring files
      ignoreRegex: (^\..*|.*\.tmp$|db.*|^lost\+found$)
      # Kafka topic to put the ingestion jobs for the worker
      topic: t-pdgs-ingestion-jobs-s3-xbip-retransfer
      # Product family accociated with the file to be ingested
      family: SESSION_RETRANSFER
      # Name of the station for EDRS sessions (4-letter code)
      stationName: S3_2
      # Mission-ID in upper case (S1,S2,S3..)
      missionId: S3
      # how many days to keep persisted data about inbox files at a minimum ( >= 0)
      station-retention-time: {{ .Values.xbip.stationRetentionTime.s3 }}
      # Set to ingnore files before a specific date (in format "yyyy-MM-ddTHH:mm:ss.SSSZ")
      ignore-files-before-date: {{ .Values.xbip.ignoreFilesBeforeDate.s3 }}
      # file name matcher for session files
      session-name-pattern: ^([A-Za-z_]{4}/)?([0-9A-Za-z_]{1})3([0-9A-Za-z_]{1})/([0-9]+)/(([0-9A-Za-z_/]+)/(ch[0|_]?[1-2]/)?(DCS_[0-9]{2}_([a-zA-Z0-9_]*)_ch([12])_(DSDB|DSIB).*\.(raw|aisp|xml|RAW|AISP|XML)))$
      # group number containing the session name
      session-name-group-index: 5

# Kafka config
kafka:
  # host:port to use for establishing the initial connection to the Kafka cluster
  bootstrap-servers: ${kafka_bootstrap-servers}
  # hostname
  hostname: ${HOSTNAME}
  # Topic name for the errors
  error-topic: ${kafka_topic_errors}
  # Kafka Producer config
  producer:
    # When greater than zero, enables retrying of failed sends
    max-retries: 10

# MongoDB config
mongodb:
  host: ${mongo_db_host:localhost}
  port: ${mongo_db_port:27017}
  database: ${mongo_db_database:s1pdgs}

# Application status configuration
status:
  # (fixed delay) period in milliseconds between 2 check if application shall be stopped or not, default is 3000
  delete-fixed-delay-ms: 3000
  # The number of consecutive processing errors leading to the state FATALERROR, default is 100
  max-error-counter-processing: 3
  # The number of consecutive MQI errors leading to the state FATALERROR, default is 100
  max-error-counter-mqi: 30
  # Timeout after no polling attempt in seconds --> AppStatus -> FAIL
  fail-after-inactivity-for-seconds: 200
