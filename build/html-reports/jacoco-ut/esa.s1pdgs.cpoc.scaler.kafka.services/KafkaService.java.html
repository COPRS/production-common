<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="fr"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../.resources/report.css" type="text/css"/><link rel="shortcut icon" href="../.resources/report.gif" type="image/gif"/><title>KafkaService.java</title><link rel="stylesheet" href="../.resources/prettify.css" type="text/css"/><script type="text/javascript" src="../.resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../.sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">S1-PDGS Cloud POC - Scaler</a> &gt; <a href="index.source.html" class="el_package">esa.s1pdgs.cpoc.scaler.kafka.services</a> &gt; <span class="el_source">KafkaService.java</span></div><h1>KafkaService.java</h1><pre class="source lang-java linenums">package esa.s1pdgs.cpoc.scaler.kafka.services;

import java.util.Arrays;
import java.util.List;
import java.util.Properties;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

import esa.s1pdgs.cpoc.scaler.kafka.KafkaMonitoringProperties;
import esa.s1pdgs.cpoc.scaler.kafka.model.ConsumerDescription;
import esa.s1pdgs.cpoc.scaler.kafka.model.ConsumerGroupsDescription;
import esa.s1pdgs.cpoc.scaler.kafka.model.PartitionDescription;
import kafka.admin.AdminClient;
import kafka.admin.AdminClient.ConsumerSummary;

/**
 * Class to access to KAFKA cluster
 * 
 * @author Cyrielle Gailliard
 */
@Service
public class KafkaService {

    /**
     * Logger
     */
<span class="fc" id="L34">    private static final Logger LOGGER =</span>
<span class="fc" id="L35">            LogManager.getLogger(KafkaService.class);</span>

    /**
     * KAFKA admin client
     */
    private final AdminClient kafkaAdminClient;

    /**
     * Properties
     */
    private final KafkaMonitoringProperties properties;

    /**
     * Constructor
     * 
     * @param kafkaAdminClient
     * @param properties
     */
    @Autowired
    public KafkaService(final AdminClient kafkaAdminClient,
<span class="fc" id="L55">            final KafkaMonitoringProperties properties) {</span>
<span class="fc" id="L56">        this.kafkaAdminClient = kafkaAdminClient;</span>
<span class="fc" id="L57">        this.properties = properties;</span>
<span class="fc" id="L58">    }</span>

    /**
     * Get the description of consumers of a given group on a given topic.&lt;br/&gt;
     * To get the offset and the lag on each partition, we connect a consumer on
     * the partitions.&lt;br/&gt;
     * The algorithm used is the one used by the KAFKA script consumer-group.sh
     * with --describe option
     * 
     * @param groupId
     * @param limitTopic
     * @return
     */
    public ConsumerGroupsDescription describeConsumerGroup(final String groupId,
            final String limitTopic) {

<span class="nc" id="L74">        ConsumerGroupsDescription r = new ConsumerGroupsDescription(groupId);</span>
<span class="nc" id="L75">        KafkaConsumer&lt;String, String&gt; consumer = null;</span>

        try {
<span class="nc" id="L78">            consumer = createKafkaConsumer(groupId);</span>

<span class="nc" id="L80">            List&lt;ConsumerSummary&gt; groupSummaries =</span>
                    scala.collection.JavaConversions
<span class="nc" id="L82">                            .seqAsJavaList(kafkaAdminClient</span>
<span class="nc" id="L83">                                    .describeConsumerGroup(groupId,</span>
<span class="nc" id="L84">                                            properties.getRequestTimeoutMs())</span>
<span class="nc" id="L85">                                    .consumers().get());</span>
<span class="nc bnc" id="L86" title="All 2 branches missed.">            for (ConsumerSummary summary : groupSummaries) {</span>
<span class="nc" id="L87">                List&lt;TopicPartition&gt; topicPartitions =</span>
                        scala.collection.JavaConversions
<span class="nc" id="L89">                                .seqAsJavaList(summary.assignment());</span>
<span class="nc" id="L90">                addConsumerDescription(r, summary, topicPartitions, limitTopic,</span>
                        consumer);
<span class="nc" id="L92">            }</span>
        } finally {
<span class="nc" id="L94">            closeKafkaConsumer(consumer);</span>
<span class="nc" id="L95">        }</span>

<span class="nc" id="L97">        return r;</span>
    }

    /**
     * Build wanted object according kafka information
     * 
     * @param result
     * @param summary
     * @param topicPartitions
     * @param limitTopic
     * @param consumer
     */
    protected void addConsumerDescription(ConsumerGroupsDescription result,
            ConsumerSummary summary, List&lt;TopicPartition&gt; topicPartitions,
            String limitTopic, KafkaConsumer&lt;String, String&gt; consumer) {
<span class="fc" id="L112">        ConsumerDescription cd = new ConsumerDescription(summary.clientId(),</span>
<span class="fc" id="L113">                summary.consumerId());</span>
<span class="fc bfc" id="L114" title="All 2 branches covered.">        for (TopicPartition tp : topicPartitions) {</span>
<span class="fc bfc" id="L115" title="All 2 branches covered.">            if (limitTopic.equalsIgnoreCase(tp.topic())) {</span>
                // Calculate offset and lag
<span class="fc" id="L117">                long currentOffset = consumer.committed(tp).offset();</span>
<span class="fc" id="L118">                consumer.assign(Arrays.asList(tp));</span>
<span class="fc" id="L119">                consumer.seekToEnd(Arrays.asList(tp));</span>
<span class="fc" id="L120">                long logEndOffset = consumer.position(tp);</span>
<span class="fc" id="L121">                long lag = logEndOffset - currentOffset;</span>
                // Create partition description
<span class="fc" id="L123">                PartitionDescription pd = new PartitionDescription(</span>
<span class="fc" id="L124">                        tp.partition(), tp.topic(), summary.consumerId(),</span>
                        currentOffset, logEndOffset, lag);
<span class="fc" id="L126">                cd.addPartition(pd);</span>
<span class="fc" id="L127">                result.getDescPerPartition().put(&quot;&quot; + pd.getId(), pd);</span>
<span class="fc" id="L128">            } else {</span>
<span class="pc bpc" id="L129" title="1 of 2 branches missed.">                if (LOGGER.isDebugEnabled()) {</span>
<span class="nc" id="L130">                    LOGGER.debug(</span>
                            &quot;Kafka partition {} ignored because invalid topic {}&quot;,
<span class="nc" id="L132">                            tp.partition(), tp.topic());</span>
                }
            }
<span class="fc" id="L135">        }</span>
<span class="fc" id="L136">        result.getDescPerConsumer().put(cd.getConsumerId(), cd);</span>
<span class="fc" id="L137">    }</span>

    /**
     * Build and get usefull Kafka client properties
     * 
     * @param groupId
     * @return
     */
    protected Properties kafkaConsumerProperties(String groupId) {
<span class="fc" id="L146">        Properties consProps = new Properties();</span>
<span class="fc" id="L147">        consProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,</span>
<span class="fc" id="L148">                properties.getBootstrapServers());</span>
<span class="fc" id="L149">        consProps.put(ConsumerConfig.CLIENT_ID_CONFIG,</span>
<span class="fc" id="L150">                properties.getClientId());</span>
<span class="fc" id="L151">        consProps.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);</span>
<span class="fc" id="L152">        consProps.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);</span>
<span class="fc" id="L153">        consProps.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG,</span>
<span class="fc" id="L154">                properties.getSessionTimeoutMs());</span>
<span class="fc" id="L155">        consProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,</span>
                StringDeserializer.class);
<span class="fc" id="L157">        consProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,</span>
                StringDeserializer.class);
<span class="fc" id="L159">        return consProps;</span>
    }

    /**
     * Open the KAFKA consumer for given group
     * 
     * @param groupId
     */
    protected KafkaConsumer&lt;String, String&gt; createKafkaConsumer(
            final String groupId) {
<span class="fc" id="L169">        return new KafkaConsumer&lt;String, String&gt;(</span>
<span class="fc" id="L170">                kafkaConsumerProperties(groupId));</span>
    }

    /**
     * Close the kafka consumer
     */
    protected void closeKafkaConsumer(
            final KafkaConsumer&lt;String, String&gt; consumer) {
<span class="fc bfc" id="L178" title="All 2 branches covered.">        if (consumer != null) {</span>
<span class="fc" id="L179">            consumer.close();</span>
        }
<span class="fc" id="L181">    }</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.5.201505241946</span></div></body></html>